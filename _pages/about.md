---
permalink: /
title: "Welcome to Banseok Kim's Academic Webpage!"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Who I am
======
  I am a persevering Yonsei undergraduate student willing to devour myself to research. 

  I find research process very enjoyable. Recently, I am conducting research on Dataset Distillation. 

  When encountering a research topic, finding unsolved problems and visualizing them in multiple aspects for analysis is the favorite part for me. Adding different ideas and monitoring performance changes is a much-awaited part, given that running codes sometimes take couple of days. However, I think rather than being overly immersed, taking a refreshment time is helpful in many ways. Sometimes, having came up with ideas taking a shower helps re-verification of what the idea is actually targetting. Staying focused on a single topic too deeply causes short-sighting. Nonetheless, I also know that none of this matters when I enjoy it! 


What I do
======
  Here is a simple demonstration of what I do!

![Editing a markdown file for a talk](/images/DD_frontpage.gif)

  Dataset distillation aims to minimize the dataset required to train model while maintaining high performance. Unlike coreset selection, dataset distillation is a process of synthesizing dataset like the outcomes above. For example, CIFAR10 dataset has 5000 images/class, which can train a ConvNet model up to 84.8% accuracy. Training the same model with 50 images/class that's been synthesized by matching training trajectory method can achieve up to 76.1% accuracy. The idea is to apply back propagation to images in order for them to mimic the parametric trajectory when models are trained on full dataset. 

  One of the design choices in dataset distillation is the number of images/class. Obviously, higher image/class mean higher performance. However, the performance changes are not linear with the images/class. Me and my collegue aims to tackle this problem with advisory from professor Bumsub Ham.


  Apart from current study, I am also developing interest in Medical AI. It seems intriguing to actually apply and develop AI models for specific purposes.

  I developed familiarity in CT reconstruction images and recently found research topics that mitigates defective instances in CT images.

  This is a demonstration of what I studied in Bio-Electrical Engineering class, a defective instance of patient moving during the CT scan.
  
![Editing a markdown file for a talk](/images/animated_image.gif)

  I am looking forward to contribution in Medical Imaging AI research community, such as mitigating noises in Low-Dose CT images.

  

